<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<link rel="shortcut icon" href="myIcon.ico">
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />

<meta name="keywords" content="Chongjian GE, CS, HKU, The University of Hong Kong">
<meta name="description" content="Chongjian GE&#39;s home page">
<meta name="google-site-verification" content="X2QFrl-bPeg9AdlMt4VKT9v6MJUSTCf-SrY3CvKt4Zs" />
<link rel="stylesheet" href="jemdoc.css" type="text/css">
<title>Chongjian GE&#39;s Homepage</title>
<!-- Google Analytics -->
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-159069803-1', 'auto');
ga('send', 'pageview');
</script>
<!-- End Google Analytics -->
<!--
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-87320911-1', 'auto');
  ga('send', 'pageview');

</script>
-->
</head>
<body>
<div id="layout-content" style="margin-top:25px">
<table>
	<tbody>
		<tr>
			<td width="670">
				<div id="toptitle">
					<h1>Chongjian GE <font face="Arial">    葛崇剑 </font></h1></div>

				<h3>Ph.D. Candidate</h3>
				<p>
					Dept. of Computer Science <br>
					The University of Hong Kong <br>
					Pokfulam, Hong Kong<br>
					<br>
					Email: <a href="mailto:rhettgee@connect.hku.hk">rhettgee AT connect DOT hku DOT hk</a><br>
				</p>
				<p>
					<a href="https://github.com/ChongjianGE"><img src="./pic/others/github_logo.png" height="30px"></a>&nbsp;&nbsp;
					<!--<a href="https://scholar.google.com/citations?user=R8mtv14AAAAJ&hl=en&oi=sra"><img src="./pic/others/google_scholar_logo.png" height="30px"></a>&nbsp;&nbsp;-->
				</p>
				</p>
			</td>
			<td>
				<img src="./pic/ChongjianGE.jpg" border="0" width="220"><br>
			</td>
		</tr><tr>
	</tr></tbody>
</table>
	
<h2>Biography </h2>
<p>
	I am currently a third-year (2020-now) Ph.D. student in the Department of Computer Science, the University of Hong Kong,
	under the co-supervision of <a href="http://luoping.me/">Prof. Ping Luo</a> and <a href="https://www.cs.hku.hk/people/academic-staff/wenping">Prof. Wenping Wang</a>.
	My research interest is computer vision and machine learning. I have done some works about fashion generation and self/semi/weak-supervised learning. <!--From 2019 to present, I have collaborated with several researchers in Tencent.-->
	<br>
	<!--<br>
	In addition to the PhD candidate, I'm an amateur photographer, filmmaking learner, cooking lover, guitar learner, day dreamer, etc. I'm currently building <i><b>my own Gallery Website</b></i> (work in process) to show some of my photographs completed in these recent years.
	-->
</p>



<h2>News</h2>
<ul>
	<li>
		[02/2023] One paper was accepted by TIP.
	</li>
	<li>
		[01/2023] One paper was accepted by ICLR 2023.
	</li>
	<li>
		[09/2022] One paper was accepted by NeurIPS 2022 Track Datasets and Benchmarks.
	</li>
	<li>
		[09/2022] One paper was accepted by NeurIPS 2022.
	</li>
	<li>
		[01/2022] Two papers were accepted by ICLR 2022 (one Oral paper, and one Spotlight paper).
	</li>
	<li>
		[10/2021] One paper was accepted by NeurIPS 2021.
	</li>
	<li>
		[07/2021] One paper was accepted by ICCV 2021.
	</li>
	<li>
		[03/2021] Two papers were accepted by CVPR 2021.
	</li>
</ul>




<h2> Publications [<a href="https://scholar.google.com/citations?user=R8mtv14AAAAJ&hl=en&oi=ao">Google Scholar</a>]</h2>
	<br>      (* indicates equal contribution)
	<br>
<table id="tbPublications" width="100%">
	<tbody>

	<tr>
		<td><center><img width="250" src="./pic/2023/iclr23_snclr.png"></center></td>
		<td>
			<font size="2">Soft Neighbors Are Positive Supporters in Contrastive Visual Representation Learning,
			<br>
			<i><b>Chongjian Ge</b>, Jiangliu Wang, Zhan Tong, Shoufa Chen, Yibing Song, and Ping Luo</i>
			<br>
			International Conference on Learning Representations (<b>ICLR</b>) 2023
			<br>
			[paper]
		</td>
	</tr>

	<tr>
		<td><center><img width="250" src="./pic/2021/nips2021_care.png"></center></td>
		<td>
			<font size="2">Revitalizing CNN Attentions via Transformers in Self-Supervised Visual Representation Learning,
			<br>
			<i><b>Chongjian Ge</b>, Youwei Liang, Yibing Song, Jianbo Jiao, Jue Wang, and Ping Luo</i>
			<br>
			Advances in Neural Information Processing Systems (<b>NeurIPS</b>) 2021
			<br>
			[<a href='https://arxiv.org/abs/2110.05340'><b>paper</b></a>|<a href='https://github.com/ChongjianGE/CARE'><b>code</b></a>|<a href='https://mp.weixin.qq.com/s/oGS4XSjO29fHdDQXV1vyvg'><b>media report</b></a>]
		</td>
	</tr>

	<tr>
		<td><center><img width="250" src="./pic/2021/cvpr2021_dcton.png"></center></td>
		<td>
			<font size="2">Disentangled Cycle Consistency for Highly-realistic Virtual Try-On,
			<br>
			<i><b>Chongjian Ge</b>, Yibing Song, Yuying Ge, Han Yang, Wei Liu, and Ping Luo</i>
			<br>
			IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>) 2021
			<br>
			[<a href='https://arxiv.org/abs/2103.09479'><b>paper</b></a>|<a href='https://github.com/ChongjianGE/DCTON'><b>code</b></a>]
		</td>
	</tr>

	<tr>
		<td><center><img width="250" src="./pic/2023/tip_neal.png"></center></td>
		<td>
			<font size="2">Rethinking Attentive Object Detection via Neural Attention Learning,
			<br>
			<i><b>Chongjian Ge</b>, Yibing Song, Chao Ma, Yuankai Qi and Ping Luo</i>
			<br>
			JOURNAL OF IEEE TRANSACTIONS ON IMAGE PROCESSING (<b>TIP</b>) 
			<br>
			[paper]
		</td>
	</tr>

	<tr>
		<td><center><img width="250" src="./pic/2022/arxiv_adaptformer.png"></center></td>
		<td>
			<font size="2">AdaptFormer: Adapting Vision Transformers for Scalable Visual Recognition,
			<br>
			<i>Shoufa Chen*, <b>Chongjian Ge*</b>, Zhan Tong, Jiangliu Wang, Yibing Song, Jue Wang, and Ping Luo</i>
			<br>
			Advances in Neural Information Processing Systems (<b>NeurIPS</b>) 2022
			<br>
			[<a href='https://arxiv.org/pdf/2205.13535.pdf'><b>paper</b></a>|<a href='https://github.com/ShoufaChen/AdaptFormer'><b>code</b></a>|<a href='http://www.shoufachen.com/adaptformer-page/'><b>project page</b></a>]
		</td>
	</tr>

	<tr>
		<td><center><img width="250" src="./pic/2022/iclr2022_evit.png"></center></td>
		<td>
			<font size="2">Not All Patches are What You Need: Expediting Vision Transformers via Token Reorganizations,
			<br>
			<i>Youwei Liang, <b>Chongjian Ge</b>, Zhan Tong, Yibing Song, Jue Wang, and Pengtao Xie</i>
			<br>
			International Conference on Learning Representations (<b>ICLR</b>) 2022 (<b>Spotlight</b>)
			<br>
			[<a href='https://arxiv.org/pdf/2202.07800.pdf'><b>paper</b></a>|<a href='https://github.com/youweiliang/evit'><b>code</b></a>]
		</td>
	</tr>

	<tr>
		<td><center><img width="250" src="./pic/2022/iclr2022_cyclemlp.png"></center></td>
		<td>
			<font size="2">	CycleMLP: A MLP-like Architecture for Dense Prediction,
			<br>
			<i>Shoufa Chen, Enze Xie, <b>Chongjian Ge</b>, Runjian Chen, Ding Liang, and Ping Luo</i>
			<br>
			International Conference on Learning Representations (<b>ICLR</b>) 2022 (<b>Oral</b>)
			<br>
			[<a href='https://arxiv.org/abs/2107.10224'><b>paper</b></a>|<a href='https://github.com/ShoufaChen/CycleMLP'><b>code</b></a>|<a href='https://mp.weixin.qq.com/s/2ajLnRtLGgKMQ8Egxhe2FQ'><b>media report</b></a>]
		</td>
	</tr>

	<tr>
		<td><center><img width="250" src="./pic/2021/cvpr2021_pfafn.png"></center></td>
		<td>
			<font size="2">Parser-Free Virtual Try-on via Distilling Appearance Flows,
			<br>
			<i>Yuying Ge, Yibing Song, Ruimao Zhang, <b>Chongjian Ge</b>, Wei Liu, and Ping Luo</i>
			<br>
			IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>) 2021
			<br>
			[<a href='https://arxiv.org/abs/2103.04559'><b>paper</b></a>|<a href='https://github.com/geyuying/PF-AFN'><b>code</b></a>]
		</td>
	</tr>

	<tr>
		<td><center><img width="250" src="./pic/2021/iccv2021_woo.png"></center></td>
		<td>
			<font size="2">Watch Only Once: An End-to-End Video Action Detection Framework,
			<br>
			<i>Shoufa Chen, Peize Sun, Enze Xie, <b>Chongjian Ge</b>, Jiannan Wu, Lan Ma, Jiajun Shen, and Ping Luo</i>
			<br>
			IEEE/CVF International Conference on Computer Vision (<b>ICCV</b>) 2021
			<br>
			[<a href='https://openaccess.thecvf.com/content/ICCV2021/papers/Chen_Watch_Only_Once_An_End-to-End_Video_Action_Detection_Framework_ICCV_2021_paper.pdf'><b>paper</b></a>|<a href='https://github.com/ShoufaChen/WOO'><b>code</b></a>]
		</td>
	</tr>

	<tr>
		<td><center><img width="250" src="./pic/2022/nips_amos.png"></center></td>
		<td>
			<font size="2">AMOS: A Large-Scale Abdominal Multi-Organ Benchmark for Versatile Medical Image Segmentation,
			<br>
				<i>Yuanfeng Ji, Haotian Bai, Jie Yang, <b>Chongjian Ge</b>, Ye Zhu, Ruimao Zhang, Zhen Li, Lingyan Zhang, Wanling Ma, Xiang Wan, Ping Luo</i>
			<br>
				Advances in Neural Information Processing Systems (<b>NeurIPS</b> 2022 Track Datasets and Benchmarks) (<b>Oral</b>)
			<br>
			[<a href='https://arxiv.org/pdf/2206.08023.pdf'><b>paper</b></a>|<a href='https://amos22.grand-challenge.org/'><b>project page</b></a>]
		</td>
	</tr>



</tbody></table>

<h2><font> Honors and Awards </font></h2>
<ul style="list-style-type:none">
	  <p style="margin-left: 0px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;"><font size="3"><meta charset="utf-8">
		  Hong Kong PhD Fellowship Scheme, HKU, 2020-2024 <br>
		  YS and Christabel Lung Postgraduate Scholarship, HKU, 2020-2021 <br>
		  Rhino-Bird Program, Tencent, 2020-2022 <br>
		  First-Class Scholarship, XJTU, 2018-2019 <br>
		  High-Voltage Scholarship, XJTU, 2017-2018 <br>
		  Pengkang Scholarship, XJTU, 2016-2017 <br>
		  Huichuan Scholarship, XJTU, 2015-2016 <br>
          Samsung Scholarship, XJTU, 2014-2015 <br>
	  </font> </p>
</ul>

<h2><font> Teaching </font></h2>
<ul>
    <li>
		From Human Vision to Machine Vision [Section 2A, 2020] [CCST9049]</br>
    </li>
    <li>
		Deep Learning [Section A, 2021] [DASC7606]</br>
    </li>
</ul>

<h2><font> Academic Service </font></h2>
<ul>
    <li>
		<b>Conference Review:</b></br>
	IEEE International Conference on Computer Vision (ICCV), 2021</br>
	IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2022</br>
	ACM International Conference on Multimedia (ACMMM), 2022</br>
	IEEE/CVF Winter Conference on Applications of Computer Vision (WACV), 2023</br>
	Neural Information Processing Systems (NeurIPS), 2022</br>
    </li>

    <li>
        <b>Journal Review:</b></br>
	IEEE Access </br>
	IEEE Journal of Biomedical and Health Informatics </br>
    </li>
</ul>


<p align=right>
	<a class="pull-right" href="#">
	<script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=6MHnf6x9T7o4yK48jgnnnSpwrnfCQ4_eJCdmT3syJjw&cl=ffffff&w=a"></script></center>
	</a>
</p>



<p><center><font>
        <br>&copy; Chongjian GE | Last updated: Dec. 2021 | <a href="photography/index.html">.</a> </font></center>
</p>

</div>
</body></html>
